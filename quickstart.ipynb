{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart to run the UDFs with local pyspark\n",
    "\n",
    "This is an example to run Arrow Flight in a local pyspark environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: docker in /home/osdi-eval/.local/lib/python3.8/site-packages (4.4.4)\n",
      "Requirement already satisfied: pyspark in /home/osdi-eval/.local/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy in /home/osdi-eval/.local/lib/python3.8/site-packages (1.20.3)\n",
      "Requirement already satisfied: pandas in /home/osdi-eval/.local/lib/python3.8/site-packages (1.4.3)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /home/osdi-eval/.local/lib/python3.8/site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/osdi-eval/.local/lib/python3.8/site-packages (from scikit-learn==1.0.2) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/osdi-eval/.local/lib/python3.8/site-packages (from scikit-learn==1.0.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/osdi-eval/.local/lib/python3.8/site-packages (from scikit-learn==1.0.2) (3.1.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/osdi-eval/.local/lib/python3.8/site-packages (from docker) (2.25.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/osdi-eval/.local/lib/python3.8/site-packages (from docker) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/osdi-eval/.local/lib/python3.8/site-packages (from docker) (1.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/osdi-eval/.local/lib/python3.8/site-packages (from pyspark) (0.10.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/osdi-eval/.local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/osdi-eval/.local/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/osdi-eval/.local/lib/python3.8/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/osdi-eval/.local/lib/python3.8/site-packages (from requests!=2.18.0,>=2.14.2->docker) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/osdi-eval/.local/lib/python3.8/site-packages (from requests!=2.18.0,>=2.14.2->docker) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/osdi-eval/.local/lib/python3.8/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.8 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install docker pyspark numpy pandas scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First build the Docker image (from repo root dir)\n",
    "\n",
    "There is a build script in the root directory to build the images.  You may need to adapt it based on your needs.\n",
    "\n",
    "For the registry (MYREG:TAG), to deploy this on your Spark cluster, use a container repo that the Spark nodes have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Dockerfile:  arrowflight/Dockerfile\n",
      "arrowflight\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      " => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (10/14)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (13/14)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      " => => exporting layers                                                    0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.2s\n",
      " => => exporting layers                                                    0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.4s\n",
      " => => exporting layers                                                    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.5s\n",
      " => => exporting layers                                                    0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.7s\n",
      " => => exporting layers                                                    0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (14/15)                                                       \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     0.8s\n",
      " => => exporting layers                                                    0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (15/15) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 38B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.8-slim-buster  0.0s\n",
      "\u001b[0m\u001b[34m => [build 1/5] FROM docker.io/library/python:3.8-slim-buster              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 382.48kB                                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 2/5] RUN python3 -m venv /venv                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 3/5] COPY arrowflight/myreqs-skl.txt /workdir/requireme  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 4/5] RUN /venv/bin/pip install  -r /workdir/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [build 5/5] WORKDIR /workdir/                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/6] COPY --from=build /venv /venv                     0.0s\n",
      "\u001b[0m\u001b[34m => [stage-1 3/6] COPY models/skl/runskl.py /workdir/user_script.py        0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 4/6] COPY arrowflight/_server.py /workdir/container_main.py   0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 5/6] COPY models/skl/rf10.skl /workdir/model                  0.1s\n",
      "\u001b[0m\u001b[34m => [stage-1 6/6] WORKDIR /workdir/                                        0.1s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.9s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.8s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:20eed1a69243a7e978a37ca38a3b562c11e81ddb8b182  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/myregname:tag                           0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! MYREG=\"myregname\" ;TAG=\"tag\";  ./build.sh arrowflight rf10.skl $MYREG:$TAG arrowflight/Dockerfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the container locally\n",
    "\n",
    "This will start a single container locally on your current machine.  \n",
    "\n",
    "To deploy on your Spark cluster, run this command on all of the nodes.  See the `prespind.sh` script in this folder.  (Ex: `./prespind.sh arrowflight/prespin_arrow`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "client = docker.from_env()\n",
    "STARTPORT = 8815\n",
    "c = client.containers.run('myregname:tag', remove=True,  detach=True,  ports={str(STARTPORT)+'/tcp': 8815})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "The main dataset is provided here: https://cagevldbpub.blob.core.windows.net/data.  Inside, it contains  folders stored in snappy.parq for (10k,100k,1m,10m,100m) rows for alphabet, which we used in all our experiments.  **It is public, but you cannot acccess the link directly via web.** It is easiest to get the full blob with az copy  `./azcopy copy --recursive https://cagevldbpub.blob.core.windows.net/data .`   \n",
    "\n",
    "(azcopy available here: https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we'll show a quick example with the alphabet10k rows table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-13 17:35:23--  https://cagevldbpub.blob.core.windows.net/data/tablesraw/alphabet10k/part-00000-c6cb6e59-f9e4-4013-a243-2ab0b717e29f-c000.snappy.parquet\n",
      "Resolving cagevldbpub.blob.core.windows.net (cagevldbpub.blob.core.windows.net)... 20.60.153.129\n",
      "Connecting to cagevldbpub.blob.core.windows.net (cagevldbpub.blob.core.windows.net)|20.60.153.129|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 306207 (299K) [application/octet-stream]\n",
      "Saving to: ‘part-00000-c6cb6e59-f9e4-4013-a243-2ab0b717e29f-c000.snappy.parquet.1’\n",
      "\n",
      "part-00000-c6cb6e59 100%[===================>] 299.03K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2022-10-13 17:35:23 (101 MB/s) - ‘part-00000-c6cb6e59-f9e4-4013-a243-2ab0b717e29f-c000.snappy.parquet.1’ saved [306207/306207]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://cagevldbpub.blob.core.windows.net/data/tablesraw/alphabet10k/part-00000-c6cb6e59-f9e4-4013-a243-2ab0b717e29f-c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start local pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load alphabet dataset into spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFile = spark.read.parquet(\"part-00000-c6cb6e59-f9e4-4013-a243-2ab0b717e29f-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFile.createOrReplaceTempView(\"alphabet10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+\n",
      "|database|  tableName|isTemporary|\n",
      "+--------+-----------+-----------+\n",
      "|        |alphabet10k|       true|\n",
      "+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Arrow Flight of figure 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, col, expr\n",
    "from typing import Iterator\n",
    "from pyspark.sql import SQLContext\n",
    "sql_context = SQLContext(spark)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### No container  (fig4/run_nocontainer.py:51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/13 17:35:46 WARN SimpleFunctionRegistry: The function predict replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.udf_skl_predict(iterator: Iterator[pandas.core.series.Series]) -> Iterator[pandas.core.series.Series]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UDF definition   \n",
    "@pandas_udf(\"long\")\n",
    "def udf_skl_predict(iterator: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "\n",
    "    path  = \"models/skl/\"\n",
    "    # This is code \"provided by the user\"\n",
    "    print()\n",
    "    def run(model, data):\n",
    "        import pickle as pkl\n",
    "\n",
    "        loaded_model = pkl.load(open(model, 'rb'))\n",
    "        print(loaded_model)\n",
    "        return loaded_model.predict(data)\n",
    "    \n",
    "    # Here is the actual UDF iterator\n",
    "    for args in iterator:\n",
    "        data_unmangled = pd.concat([feature for feature in args], axis=1)\n",
    "        predictions = run(path+\"rf10.skl\", data_unmangled.values)  \n",
    "        yield pd.Series(np.array(predictions))\n",
    "sql_context.udf.register(\"PREDICT\", udf_skl_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now time no container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "RandomForestClassifier(max_depth=10, n_estimators=10)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8194265365600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "RandomForestClassifier(max_depth=10, n_estimators=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2438809871673584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "RandomForestClassifier(max_depth=10, n_estimators=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23055672645568848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "RandomForestClassifier(max_depth=10, n_estimators=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2583658695220947\n",
      "0.23887157440185547\n",
      "358 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/osdi-eval/.local/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "RandomForestClassifier(max_depth=10, n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 1\n",
    "start = time.time()\n",
    "query = sql_context.sql(\"SELECT PREDICT(A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,1,2) as prediction FROM alphabet10k\")\n",
    "\n",
    "query.write.parquet(str(time.time())+'sqlout.txt')\n",
    "elapse = time.time()-start\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the errors about \"Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 1.0.2.\"\n",
    "This is one of the ways containers can help...when prestored models have older depedencies, containers can accomodate that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Arrow Flight (fig4/run_arrow.py:45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/13 17:36:03 WARN SimpleFunctionRegistry: The function predict_pyarrow replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.udf_skl_predict(iterator: Iterator[pandas.core.series.Series]) -> Iterator[pandas.core.series.Series]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UDF definition\n",
    "@pandas_udf(\"long\")\n",
    "def udf_skl_predict(iterator: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "\n",
    "    import pyarrow as pa\n",
    "    import pyarrow.flight as fl\n",
    "\n",
    "    from pyspark import TaskContext\n",
    "    ctx = TaskContext()\n",
    "    partid = str(ctx.partitionId())\n",
    "    port = 8815 + (int(partid) % 3)\n",
    "\n",
    "    path = 'scoreit'\n",
    "    client = fl.connect(\"grpc://127.0.0.1:\" + str(port))\n",
    "\n",
    "\n",
    "    # Here is the actual UDF iterator\n",
    "    for args in iterator:\n",
    "        data_unmangled = pd.concat([feature for feature in args], axis=1)\n",
    "\n",
    "        table = pa.Table.from_pandas(data_unmangled)\n",
    "\n",
    "        # write the data to an array on the server\n",
    "        writer, _ = client.do_put(fl.FlightDescriptor.for_path(path), table.schema)\n",
    "        writer.write_table(table, table.num_rows)\n",
    "        writer.close()\n",
    "\n",
    "        # Do the action to makeit SCORE the array on the server\n",
    "        response = client.do_action(pa.flight.Action('score', pa.allocate_buffer(0)))\n",
    "        for _ in response:  #must consume iterator, i think this is what actually triggers the action\n",
    "            pass\n",
    "\n",
    "        response = client.do_get(fl.Ticket(b'scored')).read_pandas()\n",
    "        yield response.squeeze()\n",
    "sql_context.udf.register(\"PREDICT_PYARROW\", udf_skl_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now time arrow flight local with (PREDICT_PYARROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28724074363708496\n",
      "0.29674243927001953\n",
      "0.2611050605773926\n",
      "0.27724218368530273\n",
      "0.28267979621887207\n",
      "281 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 1\n",
    "start = time.time()\n",
    "query = sql_context.sql(\"SELECT PREDICT_PYARROW(A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,1,2) as prediction FROM alphabet10k\")\n",
    "\n",
    "query.write.parquet(str(time.time())+'sqlout.txt')\n",
    "elapse = time.time()-start\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the basic setup for loading and running the data.  \n",
    "This small example just shows for 10k rows, but the rest of data is available at `https://cagevldbpub.blob.core.windows.net/data`   (tables are alpabet10k, alphabet (which is 100k but poorly named), alphabet1m, alpahbet10m, alphabet100m)\n",
    "\n",
    "To run this on your spark cluster, deploy the containers on all the remote nodes, and use the UDFs stored in the scripts for the figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### teardown container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e1ca857fc499bb68df5b0ac889a1331f97cc78fe543bf0a1fd9532eeca213f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
